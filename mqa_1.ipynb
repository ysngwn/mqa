{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "nro id : se não tiver length 16 adicionar 0 na frente\n",
        "\n",
        "instituição\n",
        "- hospital : não é de ensino, tem q marcar q não é de academia\n",
        "- mesma instituição, registros e tempos diferentes  =>  tem q agrupar\n",
        "similaridade de string -> função cosseno de PLN (ngramas)\n",
        "\n",
        "\n",
        "\n",
        "1) pegar o nome de todas as instituições do brasil (usar a lista do MEC)\n",
        "\n",
        "\n",
        "- fazer a tabela de frequência /\n",
        "eliminar oq tem pouca frequência\n",
        "- se for secretaria municipal algo assim e aparecer poucas vezes => só rotular como servidor público\n",
        "- se estiver so EACH (sem ter USP no nome), categorizar como 'outros'\n",
        "- lista de universidades\n",
        "    - tabela do ROR\n",
        "    - tabela do MEC"
      ],
      "metadata": {
        "id": "MTrrgTO6SP5l"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "00SstqcJMsXL"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "import os\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "drive.mount('/content/gdrive')\n",
        "os.chdir('/content/gdrive/My Drive/USP/2024_2º/MQA/')\n",
        "\n",
        "pd.set_option('display.max_rows', 10)\n",
        "pd.set_option('display.max_columns', None)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## READ_CSV"
      ],
      "metadata": {
        "id": "DfWK_wpL93gu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('atuacoes_2.csv', encoding='UTF-8', nrows=50000) #, dtype=str, nrows=1000)\n",
        "\n",
        "df['ANO-FIM'] = df['ANO-FIM'].fillna(2024)\n",
        "df['FLAG-DEDICACAO-EXCLUSIVA'] = df['FLAG-DEDICACAO-EXCLUSIVA'].replace('NAO', False).replace('SIM', True)\n",
        "\n",
        "df = df.astype({\n",
        "    'NRO-ID-CNPQ': int,\n",
        "    'CODIGO-INSTITUICAO': str,\n",
        "    'NOME-INSTITUICAO': str,\n",
        "    'ANO-INICIO': int,\n",
        "    'ANO-FIM': int,\n",
        "    'ENQUADRAMENTO-FUNCIONAL': str,\n",
        "    'TIPO-DE-VINCULO': str,\n",
        "    'OUTRAS-INFORMACOES': str,\n",
        "    'CARGA-HORARIA-SEMANAL': float,\n",
        "    'FLAG-DEDICACAO-EXCLUSIVA': bool\n",
        "})\n",
        "\n",
        "df = df.fillna(' ')\n",
        "df2 = df.copy()\n",
        "\n",
        "df"
      ],
      "metadata": {
        "id": "CFoGSIJUNa0V",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## TRATAMENTO"
      ],
      "metadata": {
        "id": "ebnx3vUR97YU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "df2 = df2.apply(lambda x: x.astype(str).str.upper())\n",
        "\n",
        "df2['NOME-INSTITUICAO'] = df2['NOME-INSTITUICAO'].replace('&AMP;', ' ', regex=True)\n",
        "df2['NOME-INSTITUICAO'] = df2['NOME-INSTITUICAO'].str.replace('[^\\w\\s]', ' ', regex=True)\n",
        "df2['NOME-INSTITUICAO'] = df2['NOME-INSTITUICAO'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "\n",
        "df2"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9aEDyAjASwo1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['ENQUADRAMENTO-FUNCIONAL'].value_counts()\n",
        "# apenas levar em consideracao os LIVRE, PROFESSOR_VISITANTE ?\n",
        "# la embaixo, secretaria~~ ta atrapalhando"
      ],
      "metadata": {
        "id": "se0SoSb4UfU7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df2['NOME-INSTITUICAO'].value_counts()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "Vm2RTVrwHWX8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# drop frequency less than 50\n",
        "df2 = df2[df2.groupby('NOME-INSTITUICAO')['NOME-INSTITUICAO'].transform('count').ge(50)]\n",
        "df2['NOME-INSTITUICAO'].value_counts()"
      ],
      "metadata": {
        "collapsed": true,
        "id": "6WoKduMFBwKH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# LISTA DE UNIVERSIDADES\n",
        "# https://dadosabertos.mec.gov.br/indicadores-sobre-ensino-superior/item/181-instituicoes-de-educacao-superior-do-brasil\n",
        "# https://dadosabertos.mec.gov.br/images/conteudo/Ind-ensino-superior/2022/PDA_Lista_Instituicoes_Ensino_Superior_do_Brasil_EMEC.csv\n",
        "\n",
        "'''\n",
        "criar uma categoria\n",
        "1 : educacao\n",
        "0 : outros\n",
        "'''\n",
        "\n",
        "df_uni = pd.read_csv('sup.csv', encoding='UTF-8')\n",
        "df_uni_filtered = df_uni[['NOME_DA_IES', 'SIGLA']]\n",
        "df_uni_filtered = df_uni_filtered.fillna('')\n",
        "\n",
        "df_uni_filtered = df_uni_filtered.apply(lambda x: x.astype(str).str.upper())\n",
        "df_uni_filtered['NOME_DA_IES'] = df_uni_filtered['NOME_DA_IES'].replace('&AMP;', ' ', regex=True)\n",
        "df_uni_filtered['NOME_DA_IES'] = df_uni_filtered['NOME_DA_IES'].str.replace('[^\\w\\s]', ' ', regex=True)\n",
        "df_uni_filtered['NOME_DA_IES'] = df_uni_filtered['NOME_DA_IES'].str.normalize('NFKD').str.encode('ascii', errors='ignore').str.decode('utf-8')\n",
        "\n",
        "# df_uni_filtered['NOME_E_SIGLA'] = df_uni_filtered['NOME_DA_IES'] + ' ' + df_uni_filtered['SIGLA']\n",
        "df_uni_filtered"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9DBxFuCNCvXW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP"
      ],
      "metadata": {
        "id": "l4oFZp0WWw6O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine"
      ],
      "metadata": {
        "id": "ZpUuXCDrW3II"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMILARIDADE POR NOME COMPLETO SEM SIGLA\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Vetorização TF-IDF\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['NOME_DA_IES'].values)\n",
        "tfidf_matrix_1 = vectorizer.transform(df_uni_filtered['NOME_DA_IES'].values)\n",
        "tfidf_matrix_2 = vectorizer.transform(df2['NOME-INSTITUICAO'].values)\n",
        "\n",
        "# Calcular a similaridade de cosseno\n",
        "similaridades = cosine_similarity(tfidf_matrix_2, tfidf_matrix_1)\n",
        "\n",
        "# Para cada universidade no df2, encontre o índice do nome mais similar no df1\n",
        "df2['indice_mais_similar'] = similaridades.argmax(axis=1)\n",
        "df2['similaridade_maxima'] = similaridades.max(axis=1)\n",
        "\n",
        "threshold = 0.75\n",
        "\n",
        "# Substituir os nomes no df2 pelo nome correspondente do df1\n",
        "df2['nome_corrigido'] = df2.apply(\n",
        "    lambda row: df_uni_filtered.iloc[row['indice_mais_similar']]['NOME_DA_IES']\n",
        "    if row['similaridade_maxima'] >= threshold\n",
        "    else row['NOME-INSTITUICAO'], axis=1\n",
        ")\n",
        "\n",
        "# Exibir o resultado final\n",
        "#df2[['NOME-INSTITUICAO', 'nome_corrigido']]\n",
        "#df2.loc[df2['NOME-INSTITUICAO'] != df2['nome_corrigido']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "nsJDBoggI6xy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', None)\n",
        "print(df2[['NOME-INSTITUICAO', 'nome_corrigido']].loc[df2['NOME-INSTITUICAO'] != df2['nome_corrigido']])\n",
        "pd.set_option('display.max_rows', 10)"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WCzEPI5aOpco"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# SIMILARIDADE POR SIGLA\n",
        "# NAO FUNCIONA, VER SE CONTEM\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Vetorização TF-IDF\n",
        "vectorizer = TfidfVectorizer().fit(df_uni_filtered['SIGLA'].values)\n",
        "tfidf_matrix_1 = vectorizer.transform(df_uni_filtered['SIGLA'].values)\n",
        "tfidf_matrix_2 = vectorizer.transform(df2['NOME-INSTITUICAO'].values)\n",
        "\n",
        "# Calcular a similaridade de cosseno\n",
        "similaridades = cosine_similarity(tfidf_matrix_2, tfidf_matrix_1)\n",
        "\n",
        "# Para cada universidade no df2, encontre o índice do nome mais similar no df1\n",
        "df2['indice_mais_similar_sigla'] = similaridades.argmax(axis=1)\n",
        "\n",
        "# Substituir os nomes no df2 pelo nome correspondente do df1\n",
        "df2['nome_corrigido_sigla'] = df2['indice_mais_similar_sigla'].apply(lambda idx: df_uni_filtered.iloc[idx]['SIGLA'])\n",
        "\n",
        "# Exibir o resultado final\n",
        "print(df2[['NOME-INSTITUICAO', 'nome_corrigido_sigla']])\n",
        "\n",
        "# SE TROCOU, ATRIBUIR A COLUNA 'ROTULO' COMO EDUCACAO\n",
        "# SE NÃO, ATRIBUIR A COLUNA COMO OUTROS"
      ],
      "metadata": {
        "collapsed": true,
        "id": "TfiLw6NBLyZw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### N-gram\n"
      ],
      "metadata": {
        "id": "sAfGA8JlW5iB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer_ngram = TfidfVectorizer(analyzer='char', ngram_range=(2, 4)).fit(df_uni_filtered['NOME_DA_IES'].values)\n",
        "tfidf_matrix_1_ngram = vectorizer.transform(df_uni_filtered['NOME_DA_IES'].values)\n",
        "tfidf_matrix_2_ngram = vectorizer.transform(df2['NOME-INSTITUICAO'].values)\n",
        "\n",
        "similaridades_ngram = cosine_similarity(tfidf_matrix_2_ngram, tfidf_matrix_1_ngram)\n",
        "\n",
        "# Para cada universidade no df2, encontre o índice do nome mais similar no df1\n",
        "df2['indice_mais_similar_ngram'] = similaridades_ngram.argmax(axis=1)\n",
        "df2['similaridade_maxima_ngram'] = similaridades_ngram.max(axis=1)\n",
        "\n",
        "threshold = 0.8\n",
        "\n",
        "# Substituir os nomes no df2 pelo nome correspondente do df1\n",
        "df2['nome_corrigido_ngram'] = df2.apply(\n",
        "    lambda row: df_uni_filtered.iloc[row['indice_mais_similar_ngram']]['NOME_DA_IES']\n",
        "    if row['similaridade_maxima_ngram'] >= threshold\n",
        "    else row['NOME-INSTITUICAO'], axis=1\n",
        ")\n",
        "\n",
        "# Exibir o resultado final\n",
        "#df2[['NOME-INSTITUICAO', 'nome_corrigido']]\n",
        "#df2.loc[df2['NOME-INSTITUICAO'] != df2['nome_corrigido']]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "C-_PGB8kWrG2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.set_option('display.max_rows', 10)\n",
        "print(df2[['NOME-INSTITUICAO', 'nome_corrigido_ngram']].loc[df2['NOME-INSTITUICAO'] != df2['nome_corrigido_ngram']])"
      ],
      "metadata": {
        "collapsed": true,
        "id": "WiIvrUHJX3T0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word Embedding\n",
        "- muito lentooo\n",
        "- 50k linhas : 3min"
      ],
      "metadata": {
        "id": "S9NzgnRzZA2T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm\n",
        "import spacy\n",
        "\n",
        "# AJUSTAR O CODIGO PQ NAO TROCA A COLUNA NEM NADA\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_sm\")  # Carrega um modelo pré-treinado\n",
        "df2['spacy_similarity'] = df2.apply(\n",
        "    lambda row: nlp(row['NOME-INSTITUICAO']).similarity(nlp(df_uni_filtered['NOME_DA_IES'][row['indice_mais_similar']])),\n",
        "    axis=1\n",
        ")\n",
        "\n",
        "df2"
      ],
      "metadata": {
        "id": "tOWcN-3YZDUM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Word2Vect"
      ],
      "metadata": {
        "id": "TYcdvOaacBIE"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "1g0BU_brcDQ4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# CAIO"
      ],
      "metadata": {
        "id": "VCacx6B2Wrdv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## MERGE SAME UNI"
      ],
      "metadata": {
        "id": "yMs_hr88HCSX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# merge ANO-INICIO and ANO-FIM with same CODIGO-INSTITUICAO and NRO-ID-CNPQ\n",
        "\n",
        "df_merged = df.groupby(['NRO-ID-CNPQ', 'CODIGO-INSTITUICAO']).agg(\n",
        "    earliest_date1=('ANO-INICIO', 'min'),\n",
        "    latest_date2=('ANO-FIM', 'max')\n",
        ").reset_index()\n",
        "\n",
        "\n",
        "# df.loc[df['NRO-ID-CNPQ'] == 3300778291054405]"
      ],
      "metadata": {
        "collapsed": true,
        "id": "2UILjKN8ivGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# merge column NOME-INSTITUICAO with df_merged\n",
        "\n",
        "df_drop_duplicates = df.drop_duplicates(subset=['NRO-ID-CNPQ', 'CODIGO-INSTITUICAO'])\n",
        "df_inst_merged = pd.merge(df_merged, df_drop_duplicates, on=['CODIGO-INSTITUICAO', 'NRO-ID-CNPQ'], how='left')\n",
        "df_inst_merged['NOME-INSTITUICAO'] = df_inst_merged['NOME-INSTITUICAO'].str.upper()\n",
        "\n",
        "df_inst_merged = df_inst_merged[['NRO-ID-CNPQ', 'CODIGO-INSTITUICAO', 'earliest_date1', 'latest_date2', 'NOME-INSTITUICAO']]\n",
        "df_inst_merged"
      ],
      "metadata": {
        "id": "XG2dRH1glZ6A",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## NLP"
      ],
      "metadata": {
        "id": "NRz3VRBqHGW-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# The target word for filtering (single word)\n",
        "target_word = \"UNIVERSIDADE DE SÃO PAULO\"\n",
        "\n",
        "# Step 1: Turn phrases into TF-IDF vectors\n",
        "vectorizer = TfidfVectorizer()\n",
        "phrase_vectors = vectorizer.fit_transform(df_inst_merged['NOME-INSTITUICAO'])\n",
        "\n",
        "# Step 2: Convert the target word into a vector\n",
        "# We will use the same vectorizer to transform the target word\n",
        "target_vector = vectorizer.transform([target_word])\n",
        "\n",
        "# Step 3: Compute cosine similarity between the target word and all phrases\n",
        "similarity_scores = cosine_similarity(target_vector, phrase_vectors).flatten()\n",
        "\n",
        "df_inst_merged['PREDICTION'] = similarity_scores\n",
        "\n",
        "# Step 4: Filter phrases based on a similarity threshold (e.g., > 0.1)\n",
        "threshold = 0.7\n",
        "filtered_phrases = df_inst_merged[similarity_scores > threshold]\n",
        "\n",
        "# Display the phrases that have similarity above the threshold\n",
        "#print(\"Filtered Phrases based on Cosine Similarity with the word 'sky':\")\n",
        "#print(filtered_phrases)\n",
        "df_inst_merged"
      ],
      "metadata": {
        "id": "jxrW6xb4m6T4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_inst_merged.to_csv(\"atuacoes_2_filtrado.csv\", encoding='utf8')"
      ],
      "metadata": {
        "id": "QJ74QOglqEBH"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
